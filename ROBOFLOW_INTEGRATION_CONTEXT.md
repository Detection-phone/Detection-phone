# üîÑ Kontekst zmian: Integracja modelu Roboflow head-detection

## üìã Podsumowanie zmian

Projekt zosta≈Ç zaktualizowany z **ultralytics YOLO** na **Roboflow API** do wykrywania g≈Ç√≥w w celu anonimizacji. Zmiana by≈Ça konieczna, poniewa≈º:
- Poprzedni model (YOLO) wykrywa≈Ç ca≈Çe osoby i zamazywa≈Ç procentowo (50% g√≥rnej czƒô≈õci), co b≈Çƒôdnie zamazywa≈Ço podniesione rƒôce
- Nowy model Roboflow wykrywa **tylko g≈Çowy** i zamazuje **ca≈Çy bounding box g≈Çowy** - precyzyjniej i dok≈Çadniej

---

## üîß Zmiany techniczne

### 1. **Nowa biblioteka: `roboflow`**

**Przed:**
```python
from ultralytics import YOLO
GLOBAL_YOLO_MODEL_ANONYMIZATION = YOLO("yolov8n.pt")
```

**Po:**
```python
from roboflow import Roboflow

rf = Roboflow(api_key="DAWQI4w1KCHH1MlWH7t4")
try:
    GLOBAL_YOLO_MODEL_ANONYMIZATION = rf.model("heads-detection/1")
except:
    try:
        workspace = rf.workspace("heads-detection")
        project = workspace.project("heads-detection")
        GLOBAL_YOLO_MODEL_ANONYMIZATION = project.version(1).model
    except:
        workspace = rf.workspace()
        project = workspace.project("heads-detection")
        GLOBAL_YOLO_MODEL_ANONYMIZATION = project.version(1).model
```

**Lokalizacja:** `app.py` linie 79-102

---

### 2. **Zmiana formatu danych detekcji**

**Przed (YOLO ultralytics):**
```python
results = model(frame, verbose=False)
for result in results:
    boxes = result.boxes
    for box in boxes:
        class_id = int(box.cls[0])  # 0 = person
        confidence = float(box.conf[0])
        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)  # Gotowe wsp√≥≈Çrzƒôdne
```

**Po (Roboflow):**
```python
prediction = model.predict(image_path, confidence=40, overlap=30)
results = prediction.json()

for det in results.get('predictions', []):
    confidence = det.get('confidence', 0)  # 0-1 (nie 0-100)
    center_x = int(det['x'])      # ≈örodek X
    center_y = int(det['y'])      # ≈örodek Y
    width = int(det['width'])     # Szeroko≈õƒá
    height = int(det['height'])   # Wysoko≈õƒá
    
    # Konwersja na (x1, y1, x2, y2)
    x1 = center_x - width // 2
    y1 = center_y - height // 2
    x2 = center_x + width // 2
    y2 = center_y + height // 2
```

**Kluczowe r√≥≈ºnice:**
- Roboflow zwraca **≈õrodek + wymiary** zamiast bezpo≈õrednio (x1, y1, x2, y2)
- Confidence jest w zakresie **0-1** (nie 0-100)
- Model wykrywa **tylko g≈Çowy** (nie trzeba filtrowaƒá po `class_id`)
- API wymaga **≈õcie≈ºki do pliku** (nie numpy array)

---

### 3. **Zmiana logiki anonimizacji**

**Przed (procentowe rozmycie):**
```python
# Oblicz g√≥rnƒÖ czƒô≈õƒá cia≈Ça (50% od g√≥ry)
person_height = y2 - y1
upper_body_height = int(person_height * 0.50)
roi_y2 = y1 + upper_body_height

# Zamazuj tylko g√≥rnƒÖ czƒô≈õƒá
roi = frame[y1:roi_y2, x1:x2]
```

**Po (ca≈Ça g≈Çowa):**
```python
# Zamazuj ca≈Çy bounding box g≈Çowy
roi = frame[y1:y2, x1:x2]
blur = cv2.GaussianBlur(roi, (99, 99), 30)
frame[y1:y2, x1:x2] = blur
```

**Efekt:** Zamazywanie jest teraz **precyzyjne** - tylko g≈Çowa, bez rƒÖk i innych czƒô≈õci cia≈Ça.

---

### 4. **Obs≈Çuga tymczasowych plik√≥w**

Roboflow API wymaga **≈õcie≈ºki do pliku**, nie numpy array. Dodano konwersjƒô:

```python
import tempfile

# Zapisz klatkƒô tymczasowo
with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp:
    temp_path = tmp.name
    cv2.imwrite(temp_path, frame)

try:
    # Wykryj g≈Çowy
    prediction = model.predict(temp_path, confidence=40, overlap=30)
    results = prediction.json()
    # ... przetwarzanie ...
finally:
    # Usu≈Ñ tymczasowy plik
    os.remove(temp_path)
```

**Lokalizacje:**
- `app.py`: funkcja `anonymize_frame()` (linie 839-895)
- `camera_controller.py`: metoda `anonymize_frame_logic()` (linie 1130-1180)

---

## üìÅ Zmienione pliki

### **app.py**
1. **Import:** Dodano `from roboflow import Roboflow` (linia 27)
2. **Inicjalizacja modelu:** Sekcja "2. YOLO Model dla anonimizacji" (linie 79-102)
   - Zmieniono z `YOLO("yolov8n.pt")` na `Roboflow().model("heads-detection/1")`
3. **Funkcja `anonymize_frame()`:** (linie 817-903)
   - Zmieniono format danych z YOLO na Roboflow
   - Dodano obs≈Çugƒô tymczasowych plik√≥w
   - Usuniƒôto logikƒô procentowego rozmycia

### **camera_controller.py**
1. **Klasa `AnonymizerWorker`:**
   - **Docstring:** Zaktualizowano opis (linie 1518-1525)
   - **`__init__`:** Usuniƒôto parametr `upper_body_ratio` (linia 1527-1530)
   - **Komunikaty:** Zmieniono z "g√≥rne X% cia≈Ça" na "ca≈Ça g≈Çowa" (linia 1525-1526)

2. **Metoda `_anonymize_faces()`:** (linie 1933-2028)
   - Zmieniono z YOLO API na Roboflow API
   - Zmieniono format danych (≈õrodek + wymiary ‚Üí x1, y1, x2, y2)
   - Usuniƒôto logikƒô procentowego rozmycia
   - Zamazuje teraz ca≈ÇƒÖ g≈Çowƒô

3. **Metoda `anonymize_frame_logic()`:** (linie 1102-1189)
   - Zmieniono z YOLO API na Roboflow API
   - Dodano obs≈Çugƒô tymczasowych plik√≥w
   - Zmieniono format danych
   - Zamazuje teraz ca≈ÇƒÖ g≈Çowƒô

### **requirements.txt**
- Dodano: `roboflow` (bez pinowania wersji, aby u≈ºyƒá najnowszej kompatybilnej z Python 3.13)

---

## üîë Parametry modelu Roboflow

```python
prediction = model.predict(
    image_path, 
    confidence=40,  # 0-100: Minimalna pewno≈õƒá detekcji (40%)
    overlap=30      # 0-100: Maksymalne nak≈Çadanie siƒô detekcji (30%)
)
```

**Format wyniku JSON:**
```json
{
    "predictions": [
        {
            "x": 609,              # Pozycja X ≈õrodka
            "y": 236,              # Pozycja Y ≈õrodka
            "width": 318,          # Szeroko≈õƒá bounding box
            "height": 448,         # Wysoko≈õƒá bounding box
            "confidence": 0.83,    # Pewno≈õƒá (0-1)
            "class": "head",       # Klasa obiektu
            "class_id": 0          # ID klasy
        }
    ],
    "image": {
        "width": "1280",
        "height": "720"
    }
}
```

---

## üéØ Model Roboflow

- **Workspace:** `heads-detection`
- **Projekt:** `heads-detection`
- **Wersja:** `1`
- **API Key:** `DAWQI4w1KCHH1MlWH7t4` (hardcoded w `app.py` linia 83)
- **Typ:** Head detection (wykrywa tylko g≈Çowy, nie ca≈Çe osoby)

---

## ‚ö†Ô∏è Wa≈ºne uwagi

1. **API Key:** Obecnie hardcoded w kodzie. W produkcji powinien byƒá w zmiennych ≈õrodowiskowych:
   ```python
   api_key = os.getenv("ROBOFLOW_API_KEY", "DAWQI4w1KCHH1MlWH7t4")
   ```

2. **Tymczasowe pliki:** Kod tworzy i usuwa tymczasowe pliki dla ka≈ºdej klatki. W przypadku du≈ºej liczby klatek mo≈ºe to wp≈ÇynƒÖƒá na wydajno≈õƒá.

3. **Wydajno≈õƒá:** Roboflow API mo≈ºe byƒá wolniejsze ni≈º lokalny model YOLO, poniewa≈º:
   - Wymaga zapisu/odczytu plik√≥w
   - Mo≈ºe u≈ºywaƒá API online (zale≈ºnie od konfiguracji)

4. **Fallback:** Kod ma 3 poziomy fallbacku przy ≈Çadowaniu modelu, aby obs≈Çu≈ºyƒá r√≥≈ºne warianty API Roboflow.

---

## üìä Por√≥wnanie: Przed vs Po

| Aspekt | Przed (YOLO) | Po (Roboflow) |
|--------|--------------|---------------|
| **Wykrywanie** | Ca≈Çe osoby (klasa 0) | Tylko g≈Çowy |
| **Rozmycie** | 50% g√≥rnej czƒô≈õci cia≈Ça | Ca≈Ça g≈Çowa |
| **Format danych** | (x1, y1, x2, y2) bezpo≈õrednio | ≈örodek (x, y) + width, height |
| **Confidence** | 0-1 (float) | 0-1 (float) |
| **Input** | numpy array | ≈öcie≈ºka do pliku |
| **Biblioteka** | `ultralytics` | `roboflow` |
| **Precyzja** | Niska (zamazuje rƒôce) | Wysoka (tylko g≈Çowa) |

---

## üöÄ Instalacja

```bash
pip install roboflow
```

Lub zaktualizowaƒá wszystkie zale≈ºno≈õci:
```bash
pip install -r requirements.txt
```

**Wersja:** Najnowsza kompatybilna z Python 3.13 (obecnie `roboflow==1.2.11`)

---

## üìù Przyk≈Çad u≈ºycia

```python
from roboflow import Roboflow
import cv2
import tempfile
import os

# Inicjalizacja
rf = Roboflow(api_key="DAWQI4w1KCHH1MlWH7t4")
model = rf.model("heads-detection/1")

# Wykrywanie na obrazie
image = cv2.imread("obraz.jpg")

# Zapisz tymczasowo
with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp:
    temp_path = tmp.name
    cv2.imwrite(temp_path, image)

try:
    # Predykcja
    prediction = model.predict(temp_path, confidence=40, overlap=30)
    results = prediction.json()
    
    # Przetwarzanie wynik√≥w
    for det in results.get('predictions', []):
        if det['confidence'] >= 0.4:
            center_x = int(det['x'])
            center_y = int(det['y'])
            width = int(det['width'])
            height = int(det['height'])
            
            x1 = center_x - width // 2
            y1 = center_y - height // 2
            x2 = center_x + width // 2
            y2 = center_y + height // 2
            
            # Zamazuj g≈Çowƒô
            roi = image[y1:y2, x1:x2]
            blur = cv2.GaussianBlur(roi, (99, 99), 30)
            image[y1:y2, x1:x2] = blur
finally:
    os.remove(temp_path)
```

---

## üîç G≈Ç√≥wne funkcje u≈ºywajƒÖce modelu

1. **`app.py::anonymize_frame()`** - Anonimizacja klatek dla config snapshot
2. **`camera_controller.py::_anonymize_faces()`** - Offline anonimizacja zapisanych obraz√≥w
3. **`camera_controller.py::anonymize_frame_logic()`** - Anonimizacja klatek w czasie rzeczywistym

Wszystkie trzy funkcje zosta≈Çy zaktualizowane do u≈ºywania API Roboflow.

---

## ‚úÖ Status

- ‚úÖ Model Roboflow zintegrowany
- ‚úÖ Wszystkie funkcje anonimizacji zaktualizowane
- ‚úÖ Biblioteka dodana do requirements.txt
- ‚úÖ Kompatybilno≈õƒá z Python 3.13
- ‚úÖ Testy instalacji zako≈Ñczone pomy≈õlnie

**Data zmian:** 2025-01-XX
**Wersja modelu:** heads-detection/1
**Biblioteka:** roboflow==1.2.11

