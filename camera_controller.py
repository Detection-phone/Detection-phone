import threading
import time
from datetime import datetime, timedelta, time as dt_time
import cv2
from ultralytics import YOLO
import os
from flask import current_app
from models import db, Detection, User
from queue import Queue
import json
import subprocess
import re
import numpy as np
import textwrap
from dotenv import load_dotenv

# Load environment variables from .env file (Email, Cloudinary, Vonage)
load_dotenv()

# MediaPipe nie wspiera Python 3.13 - uÅ¼ywamy OpenCV DNN jako alternatywy

# Imports for SMS notifications and Cloudinary
from vonage import Auth
from vonage_sms import Sms
from vonage_sms.requests import SmsMessage
from vonage_http_client import HttpClient
import cloudinary
import cloudinary.uploader
import cloudinary.api
import yagmail
import smtplib

class CameraController:
    def __init__(self, camera_index=0, camera_name=None):
        self.camera = None
        self.is_running = False
        self.thread = None
        self.last_frame = None
        
        # If camera_name is provided, try to find its index
        if camera_name:
            print(f"\nAttempting to find camera by name: {camera_name}")
            self.camera_index = self.find_camera_by_name(camera_name)
            if self.camera_index is None:
                print(f"Warning: Camera '{camera_name}' not found, using default index {camera_index}")
                self.camera_index = camera_index
        else:
            self.camera_index = camera_index
            
        print(f"Using camera index: {self.camera_index}")
        
        # Verify camera availability
        self._verify_camera()
        
        # Import DEFAULT_SCHEDULE from models
        from models import DEFAULT_SCHEDULE
        
        self.settings = {
            # Weekly schedule (replaces camera_start_time and camera_end_time)
            'schedule': DEFAULT_SCHEDULE.copy(),
            'blur_faces': True,  # Kontroluje czy AnonymizerWorker dziaÅ‚a (offline blur)
            'confidence_threshold': 0.2,
            'camera_index': self.camera_index,
            'camera_name': camera_name if camera_name else 'Camera 1',
            'sms_notifications': False,  # SMS notifications (Vonage + Cloudinary)
            'email_notifications': False,  # Email notifications (Yagmail + Cloudinary)
            'anonymization_percent': 50,
            # ROI as normalized [x1, y1, x2, y2] or None
            'roi_coordinates': None
        }
        self.detection_queue = Queue()
        
        # ROI zones for per-zone throttling
        self.roi_zones = []  # Lista sÅ‚ownikÃ³w, np. [{'name': 'Å‚awka 1', 'coords': {'x': 0.1, 'y': 0.1, 'w': 0.2, 'h': 0.2}}]
        
        # Per-zone throttling infrastructure
        self.alert_mute_until = {}  # SÅ‚ownik: {'nazwa_strefy': datetime_obiekt}
        self.mute_duration = timedelta(minutes=5)
        self.alert_lock = threading.Lock()  # Zabezpieczenie sÅ‚ownika
        
        # Uruchom AnonymizerWorker (offline anonimizacja + SMS notifications)
        # PrzekaÅ¼ referencjÄ™ do settings, aby worker miaÅ‚ dostÄ™p do 'sms_notifications'
        self.anonymizer_worker = AnonymizerWorker(self.detection_queue, self.settings)
        self.anonymizer_worker.start()
        print("âœ… AnonymizerWorker uruchomiony w tle")
        # Manual stop guard â€“ when True, scheduler must not auto-start the camera
        self.manual_stop_engaged = False
        
        # Initialize YOLO model
        try:
            print("Loading YOLO model...")
            self.model = YOLO('yolov8s.pt')
            print("YOLO model loaded successfully (yolov8s.pt - Small)")
            
            # Find phone class ID
            self.phone_class_id = None
            for class_id, class_name in self.model.names.items():
                if 'phone' in class_name.lower() or 'cell' in class_name.lower():
                    self.phone_class_id = class_id
                    print(f"Found phone class ID: {class_id}")
                    break
            
            if self.phone_class_id is None:
                self.phone_class_id = 67  # Default COCO class ID for cell phone
                print(f"Using default phone class ID: {self.phone_class_id}")
        except Exception as e:
            print(f"Error loading YOLO model: {e}")
            self.model = None

        # Frame skipping configuration for performance optimization
        self.frame_counter = 0
        # BÄ™dziemy analizowaÄ‡ co 10. klatkÄ™ (dla 30 FPS = 3 detekcje na sekundÄ™)
        self.process_every_n_frame = 10
        print(f"Frame skipping enabled: processing every {self.process_every_n_frame} frames")

        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

    def _open_capture(self, index):
        """Open a cv2.VideoCapture STRICTLY for the selected index.

        Order:
        1) Default backend (MSMF on Windows) - preferred for virtual cams like Iriun
        2) DirectShow (CAP_DSHOW) as the only fallback for the SAME index
        No other indices or backends are attempted here.
        """
        # Try default backend first (MSMF on Windows)
        cap = cv2.VideoCapture(index)
        if cap is not None and cap.isOpened():
            return cap
        try:
            cap.release()
        except Exception:
            pass

        # Then try DirectShow for the SAME index
        try:
            cap = cv2.VideoCapture(index, cv2.CAP_DSHOW)
            if cap is not None and cap.isOpened():
                return cap
            if cap is not None:
                cap.release()
        except Exception:
            try:
                cap.release()
            except Exception:
                pass

        return None

    def _get_camera_name_by_index(self, index):
        """Best-effort retrieval of camera device name for given index (Windows)."""
        try:
            cmd = (
                "powershell -Command \"Get-CimInstance Win32_PnPEntity | "
                "Where-Object { $_.PNPClass -eq 'Camera' } | "
                f"Select-Object -Index {index} | Select-Object -ExpandProperty Name\""
            )
            result = subprocess.run(cmd, capture_output=True, text=True, shell=True)
            if result.returncode == 0:
                name = result.stdout.strip()
                return name if name else None
        except Exception:
            pass
        return None

    def _capture_has_valid_frame(self, cap, warmup_reads=10, delay_s=0.1):
        """Read a few frames to ensure the capture delivers non-empty images.

        Some virtual cameras (e.g., Iriun) need a longer warmâ€‘up before they
        start delivering non-empty frames. Increase warmup count and delay.
        """
        try:
            for _ in range(warmup_reads):
                ret, frame = cap.read()
                if ret and frame is not None and getattr(frame, 'size', 0) > 0:
                    return True
                time.sleep(delay_s)
        except Exception:
            pass
        return False

    def _verify_camera(self):
        """Verify if the selected camera is available and working"""
        print(f"\nVerifying camera with index {self.camera_index}...")
        try:
            cap = self._open_capture(self.camera_index)
            if not cap.isOpened():
                print(f"Error: Could not open camera with index {self.camera_index}")
                # Try to find alternative camera
                print("Scanning for available cameras...")
                available_cameras = self.scan_available_cameras()
                if available_cameras:
                    print("Available cameras:")
                    for cam in available_cameras:
                        print(f"- Index {cam['index']}: {cam['name']} ({cam['resolution']}, {cam['fps']} FPS)")
                    # Use the first available camera as fallback
                    self.camera_index = available_cameras[0]['index']
                    print(f"Falling back to camera index {self.camera_index}")
                else:
                    print("No cameras found!")
            else:
                # Get camera properties
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                fps = cap.get(cv2.CAP_PROP_FPS)
                print(f"Camera opened successfully: {width}x{height} @ {fps} FPS")
            cap.release()
        except Exception as e:
            print(f"Error verifying camera: {e}")

    def update_settings(self, settings):
        """Update camera settings and handle camera state"""
        print("\nUpdating camera settings...")
        print(f"Current settings: {self.settings}")
        print(f"New settings: {settings}")
        
        # Check if camera index changed
        if 'camera_index' in settings and settings['camera_index'] != self.settings['camera_index']:
            print(f"Camera index changed from {self.settings['camera_index']} to {settings['camera_index']}")
            self.camera_index = settings['camera_index']
            self._verify_camera()
        
        # ChroÅ„ camera_name przed nadpisaniem na None
        new_camera_name = settings.get('camera_name')
        
        if new_camera_name:
            # JeÅ›li jest nowa nazwa, uÅ¼yj jej
            self.settings['camera_name'] = new_camera_name
        elif 'camera_name' not in self.settings:
            # JeÅ›li nie ma nowej i nie ma starej, ustaw domyÅ›lnÄ…
            self.settings['camera_name'] = 'Camera 1'
        # JeÅ›li nie ma nowej, ale jest stara, NIE RÃ“B NIC (zostaw starÄ…)
        
        # Zaktualizuj resztÄ™ ustawieÅ„, pomijajÄ…c camera_name (juÅ¼ obsÅ‚uÅ¼one)
        settings_to_update = {k: v for k, v in settings.items() if k != 'camera_name'}
        self.settings.update(settings_to_update)
        
        print(f"Updated settings: {self.settings}")
        
        # Check schedule and update camera state
        is_within_schedule = self._is_within_schedule()
        print(f"Within schedule: {is_within_schedule}")
        print(f"Camera running: {self.is_running}")
        
        if is_within_schedule:
            if not self.is_running:
                print("Starting camera...")
                self.start_camera()
        else:
            if self.is_running:
                print("Stopping camera...")
                self.stop_camera()
            else:
                # Start a thread to check for schedule start
                if not hasattr(self, 'schedule_check_thread') or not self.schedule_check_thread.is_alive():
                    self.schedule_check_thread = threading.Thread(target=self._check_schedule_start)
                    self.schedule_check_thread.daemon = True
                    self.schedule_check_thread.start()
                    print("Started schedule check thread")

    def _is_within_schedule(self):
        """Check if current time is within camera operation schedule (weekly)"""
        try:
            now = datetime.now()
            current_day = now.strftime('%A').lower()  # e.g., "monday"
            current_time = now.time()
            
            # Get schedule from settings
            schedule = self.settings.get('schedule', {})
            
            # Get today's schedule config
            today_schedule = schedule.get(current_day)
            
            # Check if enabled
            if not today_schedule or not today_schedule.get('enabled', False):
                print(f"\nSchedule check: {current_day.capitalize()} is disabled")
                return False
            
            # Parse start and end times
            start_time = datetime.strptime(today_schedule['start'], '%H:%M').time()
            end_time = datetime.strptime(today_schedule['end'], '%H:%M').time()
            
            print(f"\nChecking schedule:")
            print(f"Current day: {current_day.capitalize()}")
            print(f"Current time: {current_time}")
            print(f"Start time: {start_time}")
            print(f"End time: {end_time}")
            
            # Handle overnight logic (e.g., 22:00 - 06:00)
            if end_time < start_time:
                # Overnight schedule: current_time >= start_time OR current_time <= end_time
                is_within = (current_time >= start_time) or (current_time <= end_time)
            else:
                # Normal schedule: start_time <= current_time <= end_time
                is_within = start_time <= current_time <= end_time
            
            print(f"Within schedule: {is_within}")
            return is_within
        
        except Exception as e:
            print(f"Error checking schedule: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _check_schedule_start(self):
        """Thread to check when to start the camera based on schedule"""
        print("Starting schedule check thread...")
        while not self.is_running:
            within = self._is_within_schedule()
            if within:
                if not self.manual_stop_engaged:
                    print("Schedule start time reached, starting camera...")
                    self.start_camera()
                    break
            else:
                # Outside schedule â€“ clear manual stop guard so next schedule can start
                self.manual_stop_engaged = False
            time.sleep(1)  # Check every second
        print("Schedule check thread ended")

    def start_camera(self):
        """Start the camera and detection process (STRICT selected index only)."""
        if self.is_running:
            print("Camera is already running")
            return
        
        try:
            # Reset manual stop flag on explicit manual start
            self.manual_stop_engaged = False
            # Resolve target by NAME first if provided (more stable than index mapping)
            desired_name = self.settings.get('camera_name')
            resolved_index = None
            if desired_name:
                try:
                    for cam in self.scan_available_cameras():
                        if desired_name.lower() in cam.get('name', '').lower():
                            resolved_index = int(cam['index'])
                            break
                except Exception:
                    resolved_index = None

            # Fall back to stored index if name not provided/found
            if resolved_index is None:
                resolved_index = int(self.settings.get('camera_index', self.camera_index))

            self.camera_index = resolved_index
            print(f"\nInitializing camera with STRICT index {self.camera_index} (desired='{desired_name}')...")

            self.camera = None
            last_error = None

            # Try default backend (MSMF) first, then DSHOW, for the SAME index
            for backend in ('default', 'dshow'):
                if backend == 'default':
                    cap = cv2.VideoCapture(self.camera_index)
                else:
                    cap = cv2.VideoCapture(self.camera_index, cv2.CAP_DSHOW)

                if cap is not None and cap.isOpened() and self._capture_has_valid_frame(cap):
                    self.camera = cap
                    break

                # Release and record error
                if cap is not None:
                    try:
                        cap.release()
                    except Exception:
                        pass
                last_error = f"Failed to open STRICT camera index {self.camera_index} using backend {backend}"

            # If still no camera, STOP and DO NOT attempt other indices
            if self.camera is None or not self.camera.isOpened():
                if last_error:
                    print(last_error)
                print("Strict mode: not falling back to any other camera index.")
                print("\n===============================================================")
                print(f"[BÅÄ„D KRYTYCZNY] Nie moÅ¼na otworzyÄ‡ kamery (Index: {self.camera_index})!")
                print("PRZYCZYNA: Kamera jest prawdopodobnie UÅ»YWANA PRZEZ INNÄ„ APLIKACJÄ˜.")
                print("ROZWIÄ„ZANIE: Zamknij WSZYSTKIE inne programy, ktÃ³re mogÄ… uÅ¼ywaÄ‡ tej kamery")
                print("(np. okno UstawieÅ„ Windows, klient Iriun, Zoom, OBS, Teams)")
                print("i zrestartuj serwer.")
                print("===============================================================\n")
                self.is_running = False
                self.camera = None
                return
            
            # Optional assertion: verify that the opened device corresponds to desired_name
            if desired_name:
                opened_name = self._get_camera_name_by_index(self.camera_index)
                if opened_name and desired_name.lower() not in opened_name.lower():
                    # Do NOT stop; align internal settings to actual opened device to prevent confusion
                    print(f"Device name mismatch: opened='{opened_name}', desired='{desired_name}'. Using opened device and updating settings.")
                    self.settings['camera_name'] = opened_name
            
            # Configure codec and resolution with validation
            try:
                # Many virtual cams prefer MJPG on Windows
                self.camera.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*'MJPG'))
            except Exception:
                pass

            # Try preferred resolutions in order, accept first that yields valid frames
            preferred_res = [(1280, 720), (640, 480)]
            applied = None
            for w, h in preferred_res:
                try:
                    self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, w)
                    self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, h)
                except Exception:
                    continue
                # short warm-up to validate
                if self._capture_has_valid_frame(self.camera, warmup_reads=5, delay_s=0.05):
                    applied = (w, h)
                    break

            # Read back properties
            width = int(self.camera.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(self.camera.get(cv2.CAP_PROP_FRAME_HEIGHT))
            fps = self.camera.get(cv2.CAP_PROP_FPS)
            print(f"Camera initialized successfully: {width}x{height} @ {fps} FPS (requested={applied})")
            
            self.is_running = True
            print(f"Camera started successfully with index {self.camera_index}")
            
            # Start camera loop in a separate thread
            self.camera_thread = threading.Thread(target=self._camera_loop)
            self.camera_thread.daemon = True
            self.camera_thread.start()
            print("Camera thread started")
            
        except Exception as e:
            print(f"Error starting camera: {e}")
            self.is_running = False
            if self.camera is not None:
                self.camera.release()
                self.camera = None

    def stop_camera(self):
        """Stop the camera and cleanup resources (GUI cleanup in main thread)."""
        print("\nStopping camera...")
        # Engage manual stop so scheduler won't auto-start within current schedule window
        self.manual_stop_engaged = True
        self.is_running = False
        
        # Ask the worker thread to finish and wait briefly (non-blocking join)
        if hasattr(self, 'camera_thread') and self.camera_thread is not None:
            try:
                self.camera_thread.join(timeout=1.0)
            except Exception:
                pass
        
        # Release capture if still open
        if self.camera is not None:
            try:
                self.camera.release()
            except Exception:
                pass
            self.camera = None
        
        # Destroy OpenCV windows from the caller (main) thread
        try:
            try:
                cv2.destroyWindow('Phone Detection')
            except Exception:
                cv2.destroyAllWindows()
            # Let GUI process window teardown
            # for _ in range(5):
            #     cv2.waitKey(1)
        except Exception:
            pass
        
        print("Camera stopped")
        
        # Start schedule check thread for next schedule
        if not hasattr(self, 'schedule_check_thread') or not self.schedule_check_thread.is_alive():
            self.schedule_check_thread = threading.Thread(target=self._check_schedule_start)
            self.schedule_check_thread.daemon = True
            self.schedule_check_thread.start()
            print("Started schedule check thread for next schedule")

    def update_roi_zones(self, new_zones_list):
        """Publiczna metoda do aktualizacji stref ROI z zewnÄ…trz (np. z app.py)."""
        print(f"Aktualizowanie stref ROI. ZaÅ‚adowano {len(new_zones_list)} stref.")
        self.roi_zones = new_zones_list

    def find_matching_zone(self, center_x, center_y, frame_width, frame_height):
        """Sprawdza, czy punkt (x, y) detekcji wpada w ktÃ³rÄ…Å› ze zdefiniowanych stref ROI."""
        # Znormalizuj wspÃ³Å‚rzÄ™dne detekcji (0.0 do 1.0)
        norm_x = center_x / frame_width
        norm_y = center_y / frame_height

        for zone in self.roi_zones:
            # ZakÅ‚adamy, Å¼e 'coords' to {'x': 0.1, 'y': 0.1, 'w': 0.2, 'h': 0.2} w formacie znormalizowanym
            coords = zone.get('coords', {})
            if not isinstance(coords, dict):
                continue
            
            x = coords.get('x', 0)
            y = coords.get('y', 0)
            w = coords.get('w', 0)
            h = coords.get('h', 0)
            
            # Oblicz x2 i y2 (prawy dolny rÃ³g)
            x2 = x + w
            y2 = y + h

            if x <= norm_x <= x2 and y <= norm_y <= y2:
                return zone.get('name')  # ZwrÃ³Ä‡ nazwÄ™ strefy (np. "Å‚awka 1")

        return None  # Nie znaleziono dopasowania

    def trigger_throttled_notification(self, zone_name, frame, confidence):
        """Sprawdza wyciszenie i wysyÅ‚a powiadomienie dla danej strefy."""
        now = datetime.now()

        with self.alert_lock:
            # 1. SprawdÅº, czy strefa jest wyciszona
            if zone_name in self.alert_mute_until:
                if now < self.alert_mute_until[zone_name]:
                    # JEST WYCISZONA. Ignoruj.
                    mute_until_str = self.alert_mute_until[zone_name].strftime('%H:%M:%S')
                    print(f"ðŸ”‡ Strefa '{zone_name}' jest wyciszona do {mute_until_str}. Pomijam alert.")
                    return
                else:
                    # Czas wyciszenia minÄ…Å‚
                    self.alert_mute_until.pop(zone_name, None)

            # 2. NIE JEST WYCISZONA. WyÅ›lij alerty.
            print(f"ðŸ“± WYKRYTO TELEFON w strefie '{zone_name}'. WysyÅ‚anie alertÃ³w...")

            # WywoÅ‚aj _handle_detection z informacjÄ… o strefie
            self._handle_detection(frame, confidence, zone_name)

            # 3. Ustaw nowe wyciszenie dla TEJ STREFY
            print(f"â° Ustawiam 5-minutowe wyciszenie dla strefy '{zone_name}'.")
            self.alert_mute_until[zone_name] = now + self.mute_duration

    def _handle_detection(self, frame, confidence, zone_name=None):
        """
        ObsÅ‚uguje wykrycie telefonu:
        1. Zapisuje ORYGINALNÄ„ klatkÄ™ (bez zamazanych twarzy!)
        2. Dodaje do kolejki dla AnonymizerWorker z ZAMROÅ»ONÄ„ konfiguracjÄ… blur
        3. Worker zamaÅ¼e twarze (jeÅ›li wÅ‚Ä…czone) i doda do DB
        """
        try:
            # Create detections directory if it doesn't exist
            os.makedirs('detections', exist_ok=True)
            
            # Save ORIGINAL image (without blurred faces!)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'phone_{timestamp}.jpg'
            filepath = os.path.join('detections', filename)
            
            success = cv2.imwrite(filepath, frame)
            if not success:
                raise Exception("Failed to save detection image")
            
            print(f"ðŸ’¾ Zapisano ORYGINALNÄ„ klatkÄ™: {filepath}")
            
            # KLUCZOWE: ZamroÅº konfiguracjÄ™ blur w momencie detekcji
            # Ta wartoÅ›Ä‡ zostanie przekazana do workera razem z zadaniem
            should_blur = self.settings.get('blur_faces', True)
            
            # Dodaj do kolejki dla AnonymizerWorker
            # Worker zamaÅ¼e twarze (jeÅ›li should_blur=True) i zapisze do DB
            detection_data = {
                'filepath': filepath,  # PeÅ‚na Å›cieÅ¼ka
                'confidence': confidence,
                'should_blur': should_blur,  # Pipe the setting!
                'zone_name': zone_name  # Nazwa strefy (np. "Å‚awka 1") lub None
            }
            self.detection_queue.put(detection_data)
            blur_status = "z zamazaniem" if should_blur else "BEZ zamazania"
            print(f"ðŸ“¤ Dodano do kolejki anonimizacji {blur_status} (rozmiar: {self.detection_queue.qsize()})")
            
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d zapisu detekcji: {e}")
            if 'filepath' in locals() and os.path.exists(filepath):
                os.remove(filepath)

    # USUNIÄ˜TE: process_detection_queue() - teraz robi to AnonymizerWorker asynchronicznie

    def _camera_loop(self):
        """Main camera loop for capturing and processing frames"""
        print("Starting camera loop...")
        consecutive_failures = 0
        
        while self.is_running:
            try:
                # Check if we're still within schedule (weekly check)
                if not self._is_within_schedule():
                    print(f"Outside schedule, stopping camera (signal)")
                    self.is_running = False
                    break
                
                # Sprawdzenie, czy kamera jest otwarta
                if not self.camera or not self.camera.isOpened():
                    print("Camera is not opened, attempting to reopen...")
                    try:
                        if self.camera is not None:
                            self.camera.release()
                        self.camera = self._open_capture(self.camera_index)
                        if self.camera is None or not self.camera.isOpened():
                            print("Failed to reopen camera, waiting...")
                            time.sleep(1)
                            continue
                        # Reset properties after reopen
                        self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
                        self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
                        print("Camera reopened successfully")
                    except Exception as e:
                        print(f"Error reopening camera: {e}")
                        time.sleep(1)
                        continue
                
                ret, frame = self.camera.read()
                
                # KULODOODPORNY GUARD CLAUSE: Sprawdzenie MUSI byÄ‡ tutaj, BEZPOÅšREDNIO po read()
                # Przed ustawieniem self.last_frame - zapobiega wyÅ›cigowi wÄ…tkÃ³w
                # Sprawdzamy ret, None i rozmiar klatki (uszkodzone klatki z Iriun mogÄ… mieÄ‡ ret=True ale size=0)
                frame_is_invalid = False
                try:
                    # SprawdÅº podstawowe warunki
                    if not ret or frame is None:
                        frame_is_invalid = True
                    else:
                        # SprawdÅº czy klatka ma prawidÅ‚owy rozmiar (uszkodzone klatki mogÄ… mieÄ‡ size=0)
                        if not hasattr(frame, 'size') or frame.size == 0:
                            frame_is_invalid = True
                except Exception as e:
                    # JeÅ›li jakakolwiek walidacja siÄ™ nie powiedzie, klatka jest nieprawidÅ‚owa
                    print(f"BÅ‚Ä…d walidacji klatki (nieoczekiwany): {e}")
                    frame_is_invalid = True
                
                if frame_is_invalid:
                    print("OstrzeÅ¼enie: Pusta lub uszkodzona klatka (ret=False, frame=None lub frame.size=0). Pomijanie.")
                    consecutive_failures += 1
                    # Try to recover by re-opening the camera after a few failures
                    if consecutive_failures >= 5:
                        print("Too many read failures, attempting to reopen camera...")
                        try:
                            if self.camera is not None:
                                self.camera.release()
                            self.camera = self._open_capture(self.camera_index)
                            if self.camera is None or not self.camera.isOpened() or not self._capture_has_valid_frame(self.camera):
                                print("Reopen failed; will retry shortly")
                                time.sleep(1)
                                continue
                            # Reset properties after reopen
                            self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
                            self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
                            consecutive_failures = 0
                            print("Camera reopened successfully")
                        except Exception as e:
                            print(f"Error while reopening camera: {e}")
                            time.sleep(1)
                            continue
                    # Daj kamerze chwilÄ™ na odzyskanie
                    time.sleep(0.1)
                    continue  # Przeskocz do nastÄ™pnej iteracji pÄ™tli - NIE ustawiamy last_frame!
                
                # Dopiero teraz klatka jest bezpieczna - ustawiamy last_frame PRZED wszystkimi innymi operacjami
                consecutive_failures = 0
                try:
                    self.last_frame = frame.copy()
                except Exception as e:
                    print(f"Error copying frame to last_frame: {e}")
                    time.sleep(0.1)
                    continue
                
                # Dodatkowa walidacja: sprawdÅº szczegÃ³Å‚owe wymiary klatki (shape)
                # (Podstawowa walidacja size juÅ¼ zostaÅ‚a wykonana w guard clause powyÅ¼ej)
                try:
                    # Validate frame dimensions (wysokoÅ›Ä‡ i szerokoÅ›Ä‡)
                    h, w = frame.shape[:2]
                    if h == 0 or w == 0:
                        print("BÅ‚Ä…d odczytu klatki (zerowe wymiary shape), pomijanie...")
                        time.sleep(0.1)
                        continue
                except (AttributeError, IndexError, TypeError) as e:
                    print(f"BÅ‚Ä…d walidacji wymiarÃ³w klatki: {e}")
                    time.sleep(0.1)
                    continue
                
                # KLUCZOWE: NIE zamazuj twarzy w real-time!
                # Zamazywanie bÄ™dzie robione OFFLINE przez AnonymizerWorker
                # WyÅ›wietlamy ORYGINALNÄ„ klatkÄ™ bez zamazania
                try:
                    display_frame = frame.copy()
                except Exception as e:
                    print(f"Error copying frame for display: {e}")
                    time.sleep(0.1)
                    continue
                
                # Increment frame counter for skipping logic
                self.frame_counter += 1
                
                # --- KLUCZOWA LOGIKA POMIJANIA KLATEK ---
                # JeÅ›li to nie jest co 10. klatka, przeskocz do nastÄ™pnej iteracji
                # To pozwala na pÅ‚ynne dziaÅ‚anie streamu, a detekcjÄ™ wykonujemy tylko co 10. klatkÄ™
                if self.frame_counter % self.process_every_n_frame != 0:
                    continue  # PomiÅ„ detekcjÄ™ dla tej klatki, ale stream dziaÅ‚a normalnie
                
                # --- TEN KOD WYKONA SIÄ˜ TERAZ TYLKO CO 10. KLATKÄ˜ ---
                # (ZakÅ‚adajÄ…c 30 FPS = 3 detekcje na sekundÄ™)
                if self.model is not None:
                    try:
                        # Validate display_frame exists and is valid before using
                        if display_frame is None or display_frame.size == 0:
                            continue
                            
                        results = self.model(frame, verbose=False)  # UÅ¼ywa ORYGINALNEJ klatki
                        # Pobierz wymiary klatki do normalizacji
                        frame_height, frame_width = frame.shape[:2]
                        
                        for result in results:
                            if result.boxes is None:
                                continue
                            boxes = result.boxes
                            for box in boxes:
                                # Validate box has valid xyxy data
                                if box.xyxy is None or len(box.xyxy) == 0 or len(box.xyxy[0]) < 4:
                                    continue
                                class_id = int(box.cls[0])
                                confidence = float(box.conf[0])
                                if class_id == self.phone_class_id and confidence >= self.settings['confidence_threshold']:
                                    # Oblicz Å›rodek detekcji
                                    bx1, by1, bx2, by2 = map(float, box.xyxy[0])
                                    center_x = (bx1 + bx2) / 2.0
                                    center_y = (by1 + by2) / 2.0
                                    
                                    # ZnajdÅº, w ktÃ³rej strefie jest telefon
                                    matched_zone = self.find_matching_zone(center_x, center_y, frame_width, frame_height)
                                    
                                    if matched_zone:
                                        # Mamy trafienie w strefÄ™! Uruchom logikÄ™ throttlingu
                                        self.trigger_throttled_notification(matched_zone, frame.copy(), confidence)
                                    elif len(self.roi_zones) > 0:
                                        # SÄ… zdefiniowane strefy, ale telefon nie trafiÅ‚ w Å¼adnÄ… - pomijamy
                                        continue
                                    else:
                                        # Brak zdefiniowanych stref - uÅ¼yj starej logiki (kompatybilnoÅ›Ä‡ wsteczna)
                                        # SprawdÅº legacy ROI jeÅ›li istnieje
                                        roi = self.settings.get('roi_coordinates')
                                        allow = True
                                        if roi and isinstance(roi, (list, tuple)) and len(roi) == 4:
                                            try:
                                                x1f, y1f, x2f, y2f = [float(v) for v in roi]
                                            except Exception:
                                                x1f, y1f, x2f, y2f = 0.0, 0.0, 1.0, 1.0
                                            norm_cx = center_x / max(1, frame_width)
                                            norm_cy = center_y / max(1, frame_height)
                                            allow = (x1f <= norm_cx <= x2f) and (y1f <= norm_cy <= y2f)
                                        if not allow:
                                            continue
                                        
                                        # UÅ¼yj starej metody _handle_detection bez strefy
                                        self._handle_detection(frame.copy(), confidence, None)

                                    # Rysuj bounding box na wyÅ›wietlanej klatce
                                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                                    
                                    # Validate and clamp coordinates to frame bounds
                                    x1 = max(0, min(x1, frame_width - 1))
                                    y1 = max(0, min(y1, frame_height - 1))
                                    x2 = max(0, min(x2, frame_width - 1))
                                    y2 = max(0, min(y2, frame_height - 1))
                                    
                                    # Ensure valid rectangle (x2 > x1, y2 > y1)
                                    if x2 > x1 and y2 > y1:
                                        try:
                                            cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 0, 255), 2)
                                            # Clamp text position to avoid negative y
                                            text_y = max(10, y1 - 10)
                                            label = f"Phone: {confidence:.2f}"
                                            if matched_zone:
                                                label += f" [{matched_zone}]"
                                            cv2.putText(display_frame, label, (x1, text_y),
                                                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)
                                        except Exception as draw_err:
                                            print(f"Error drawing phone box: {draw_err}")
                                    
                                    # Opcjonalnie: break, jeÅ›li wystarczy nam jeden telefon na klatkÄ™
                                    # break
                                # Draw bounding box for person (tylko na wyÅ›wietlanej klatce)
                                if class_id == 0 and confidence >= 0.5:  # 0 is 'person' in COCO
                                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                                    
                                    # Validate and clamp coordinates to frame bounds
                                    x1 = max(0, min(x1, frame_width - 1))
                                    y1 = max(0, min(y1, frame_height - 1))
                                    x2 = max(0, min(x2, frame_width - 1))
                                    y2 = max(0, min(y2, frame_height - 1))
                                    
                                    # Ensure valid rectangle (x2 > x1, y2 > y1)
                                    if x2 > x1 and y2 > y1:
                                        try:
                                            cv2.rectangle(display_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                                            # Clamp text position to avoid negative y
                                            text_y = max(10, y1 - 10)
                                            cv2.putText(display_frame, f'Person: {confidence:.2f}', (x1, text_y),
                                                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
                                        except Exception as draw_err:
                                            print(f"Error drawing person box: {draw_err}")
                    except Exception as e:
                        print(f"Error processing frame with YOLO: {e}")
                
                # Display disabled in server mode to avoid GUI blocking
                # cv2.imshow('Phone Detection', display_frame)
                # if cv2.waitKey(1) & 0xFF == ord('q'):
                #     break
                
                # AnonymizerWorker przetwarza kolejkÄ™ automatycznie w tle
                
            except cv2.error as e:
                # Specjalna obsÅ‚uga bÅ‚Ä™dÃ³w OpenCV (np. cv::Mat::Mat)
                print(f"BÅÄ„D KRYTYCZNY OpenCV (cv::Mat::Mat?) w pÄ™tli kamery: {e}")
                print("PominiÄ™cie klatki i kontynuacja...")
                time.sleep(0.5)  # DÅ‚uÅ¼sza pauza
                continue
            except Exception as e:
                # Åapanie wszystkich innych bÅ‚Ä™dÃ³w
                print(f"Nieoczekiwany bÅ‚Ä…d w pÄ™tli kamery: {e}")
                time.sleep(1)
                continue
        
        # Cleanup only capture here (no GUI operations in worker thread)
        try:
            if self.camera is not None:
                self.camera.release()
                self.camera = None
        except Exception:
            pass
        print("Camera loop ended")

    def get_current_frame_bytes(self):
        """Return the latest captured frame encoded as JPEG bytes, or None if unavailable."""
        try:
            if self.last_frame is None:
                return None
            # Encode to JPEG
            success, buffer = cv2.imencode('.jpg', self.last_frame)
            if not success:
                return None
            return buffer.tobytes()
        except Exception:
            return None

    def get_last_frame(self):
        """Return the latest raw frame (numpy array) or None if unavailable."""
        try:
            return self.last_frame
        except Exception:
            return None

    def __del__(self):
        """Czysty shutdown - zatrzymaj kamerÄ™ i workera"""
        self.stop_camera()
        
        # Zatrzymaj AnonymizerWorker
        if hasattr(self, 'anonymizer_worker'):
            print("ðŸ›‘ Zatrzymywanie AnonymizerWorker...")
            self.detection_queue.put(None)  # SygnaÅ‚ zakoÅ„czenia
            self.anonymizer_worker.stop()
            self.anonymizer_worker.join(timeout=5)

    @staticmethod
    def _open_capture_static(index):
        """Static helper to open VideoCapture (same logic as instance method)"""
        # Try default backend first (MSMF on Windows)
        cap = cv2.VideoCapture(index)
        if cap is not None and cap.isOpened():
            return cap
        try:
            cap.release()
        except Exception:
            pass

        # Then try DirectShow for the SAME index
        try:
            cap = cv2.VideoCapture(index, cv2.CAP_DSHOW)
            if cap is not None and cap.isOpened():
                return cap
            if cap is not None:
                cap.release()
        except Exception:
            try:
                cap.release()
            except Exception:
                pass

        return None

    @staticmethod
    def _capture_has_valid_frame_static(cap, warmup_reads=10, delay_s=0.1):
        """Static helper to check if capture delivers valid frames"""
        try:
            # Try to read at least one valid frame
            for attempt in range(warmup_reads):
                ret, frame = cap.read()
                if ret and frame is not None:
                    # Check if frame has valid size
                    frame_size = getattr(frame, 'size', 0)
                    if frame_size > 0:
                        # Additional check: frame should have valid dimensions
                        try:
                            h, w = frame.shape[:2]
                            if h > 0 and w > 0:
                                return True
                        except (AttributeError, IndexError, TypeError):
                            pass
                if attempt < warmup_reads - 1:  # Don't sleep on last attempt
                    time.sleep(delay_s)
        except Exception as e:
            print(f"    âš ï¸ Exception in _capture_has_valid_frame_static: {e}")
        return False

    @staticmethod
    def scan_available_cameras():
        """Scan and list all available camera devices and their indices"""
        available_cameras = []
        
        print("\nðŸ” Starting camera scan...")
        
        # First, get all camera-like devices from Windows using PowerShell
        # Search for both Camera and Image device classes (Iriun may be in Image)
        all_camera_devices = []
        try:
            # Search for Camera class devices
            cmd = "powershell -Command \"Get-CimInstance Win32_PnPEntity | Where-Object { $_.PNPClass -eq 'Camera' -or $_.PNPClass -eq 'Image' } | Select-Object Name, DeviceID, Manufacturer, Description, PNPClass | ConvertTo-Json\""
            result = subprocess.run(cmd, capture_output=True, text=True, shell=True, timeout=10)
            if result.returncode == 0 and result.stdout.strip():
                devices = json.loads(result.stdout)
                if not isinstance(devices, list):
                    devices = [devices]
                
                print(f"ðŸ“‹ Found {len(devices)} camera-like devices in Windows:")
                for device in devices:
                    device_name = device.get('Name', 'Unknown Device')
                    print(f"  - {device_name} (PNPClass: {device.get('PNPClass', 'Unknown')})")
                    all_camera_devices.append({
                        'name': device_name,
                        'pnpmclass': device.get('PNPClass', 'Unknown')
                    })
        except Exception as e:
            print(f"âš ï¸ Warning: Could not get camera list from Windows: {e}")
            import traceback
            traceback.print_exc()
        
        # Try to open cameras with indices 0-15 (increased range for virtual cameras)
        for index in range(16):
            cap = None
            # Use static helper method
            try:
                print(f"  ðŸ” Attempting to open camera index {index}...")
                cap = CameraController._open_capture_static(index)
                if cap is None:
                    print(f"    âŒ Camera {index} could not be opened (returned None)")
                    continue
                if not cap.isOpened():
                    print(f"    âŒ Camera {index} object created but isOpened() returned False")
                    try:
                        cap.release()
                    except:
                        pass
                    continue
                print(f"    âœ… Camera {index} opened successfully!")
            except Exception as e:
                print(f"    âš ï¸ Exception opening camera {index}: {e}")
                import traceback
                traceback.print_exc()
                continue
            
            if cap is None or not cap.isOpened():
                continue
                
            if cap.isOpened():
                print(f"  ðŸ“¹ Testing camera index {index}...")
                
                # Get camera properties first (these should work even if frame reading is slow)
                try:
                    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    fps = cap.get(cv2.CAP_PROP_FPS)
                    
                    # If width/height are 0, camera might not be initialized yet
                    if width == 0 or height == 0:
                        print(f"    âš ï¸ Camera {index} opened but properties are 0x0, trying to read a frame...")
                        # Try to read a frame to initialize
                        ret, test_frame = cap.read()
                        if ret and test_frame is not None:
                            width = test_frame.shape[1] if len(test_frame.shape) > 1 else 0
                            height = test_frame.shape[0] if len(test_frame.shape) > 0 else 0
                        else:
                            # Still try with default values - some cameras need to be actively used
                            width = 640
                            height = 480
                            print(f"    âš ï¸ Using default resolution 640x480 for camera {index}")
                except Exception as e:
                    print(f"    âš ï¸ Error getting camera properties: {e}, using defaults")
                    width = 640
                    height = 480
                    fps = 30
                
                # Try to verify frame reading (but don't be too strict - some cameras work even if this fails)
                has_valid_frame = False
                try:
                    has_valid_frame = CameraController._capture_has_valid_frame_static(cap, warmup_reads=3, delay_s=0.1)
                    if not has_valid_frame:
                        # Try one more time with longer delay for virtual cameras
                        time.sleep(0.3)
                        has_valid_frame = CameraController._capture_has_valid_frame_static(cap, warmup_reads=5, delay_s=0.15)
                except Exception as e:
                    print(f"    âš ï¸ Frame validation error (non-critical): {e}")
                
                if not has_valid_frame:
                    print(f"    âš ï¸ Camera {index} cannot deliver valid frames yet, but will include it anyway (may work when actively used)")
                    # Don't reject - include camera anyway, it might work when actively used
                
                print(f"    âœ… Camera {index} is working! ({width}x{height} @ {fps} FPS)")
                
                # Try to get camera name
                name = f"Camera {index}"
                
                # Try to match by querying Windows for this specific OpenCV index
                # Note: OpenCV index may not match Windows device index directly
                try:
                    # Approach 1: Try to get name using DirectShow backend property (if available)
                    try:
                        backend_name = cap.getBackendName()
                        print(f"    ðŸ“· Camera backend: {backend_name}")
                    except:
                        pass
                    
                    # Approach 2: If we have all_camera_devices list, try to match by index
                    # This is our primary method since we already have the list
                    if len(all_camera_devices) > 0:
                        if index < len(all_camera_devices):
                            name = all_camera_devices[index]['name']
                            print(f"    âœ… Using name from pre-scanned device list: {name}")
                        else:
                            # If index is beyond our list, try to find by searching all devices
                            # This handles cases where OpenCV index doesn't match Windows index order
                            print(f"    âš ï¸ Camera index {index} beyond pre-scanned list, trying PowerShell query...")
                    
                    # Approach 3: Try PowerShell query for Camera class at this index (fallback)
                    if name == f"Camera {index}":  # If we still don't have a name
                        cmd = f"powershell -Command \"Get-CimInstance Win32_PnPEntity | Where-Object {{ $_.PNPClass -eq 'Camera' }} | Select-Object -Index {index} | Select-Object -ExpandProperty Name\""
                        result = subprocess.run(cmd, capture_output=True, text=True, shell=True, timeout=5)
                        if result.returncode == 0 and result.stdout.strip():
                            name = result.stdout.strip()
                            print(f"    âœ… Got name from Windows (Camera class): {name}")
                        else:
                            # Approach 4: Try Image class (for virtual cameras like Iriun)
                            cmd = f"powershell -Command \"Get-CimInstance Win32_PnPEntity | Where-Object {{ $_.PNPClass -eq 'Image' }} | Select-Object -Index {index} | Select-Object -ExpandProperty Name\""
                            result = subprocess.run(cmd, capture_output=True, text=True, shell=True, timeout=5)
                            if result.returncode == 0 and result.stdout.strip():
                                name = result.stdout.strip()
                                print(f"    âœ… Got name from Windows (Image class): {name}")
                    
                    # Approach 5: Search all_camera_devices for Iriun (in case index mismatch)
                    # This is especially useful for Iriun which might be on a different index
                    if "Iriun" not in name and "iriun" not in name.lower() and len(all_camera_devices) > 0:
                        for device in all_camera_devices:
                            if "Iriun" in device['name'] or "iriun" in device['name'].lower():
                                # Found Iriun in the list - if this is the only Iriun, assume it's this camera
                                name = device['name']
                                print(f"    âœ… Found Iriun in device list: {name}")
                                break
                                
                except Exception as e:
                    print(f"    âš ï¸ Warning: Could not get name for camera index {index}: {e}")
                
                # Normalize Iriun Webcam name (case-insensitive)
                if "Iriun" in name or "iriun" in name.lower():
                    name = "Iriun Webcam"
                    print(f"    âœ… Normalized to: Iriun Webcam")
                
                # Try to get more detailed device information
                try:
                    cmd = f"powershell -Command \"Get-CimInstance Win32_PnPEntity | Where-Object {{ $_.PNPClass -eq 'Camera' -or $_.PNPClass -eq 'Image' }} | Select-Object -Index {index} | Select-Object -Property Name, DeviceID, Manufacturer, Description, PNPClass | ConvertTo-Json\""
                    result = subprocess.run(cmd, capture_output=True, text=True, shell=True, timeout=5)
                    if result.returncode == 0 and result.stdout.strip():
                        device_info = json.loads(result.stdout)
                        print(f"    ðŸ“· Device info: {device_info}")
                except Exception as e:
                    pass  # Silently ignore errors in detailed info
                
                available_cameras.append({
                    'index': index,
                    'name': name,
                    'resolution': f"{width}x{height}",
                    'fps': fps
                })
                
                cap.release()
            else:
                try:
                    cap.release()
                except Exception:
                    pass
        
        print(f"âœ… Scan complete: Found {len(available_cameras)} available cameras")
        return available_cameras

    def find_camera_by_name(self, camera_name):
        """Find camera index by device name using Media Foundation API"""
        try:
            print(f"\nðŸ” Searching for camera: {camera_name}")
            
            # First try to find by exact name match in both Camera and Image classes
            cmd = "powershell -Command \"Get-CimInstance Win32_PnPEntity | Where-Object { $_.PNPClass -eq 'Camera' -or $_.PNPClass -eq 'Image' } | Select-Object Name, DeviceID, Manufacturer, Description, PNPClass | ConvertTo-Json\""
            result = subprocess.run(cmd, capture_output=True, text=True, shell=True, timeout=10)
            
            if result.returncode != 0:
                print(f"Error getting camera list: {result.stderr}")
                # Fallback to scanning
                available_cameras = self.scan_available_cameras()
                for camera in available_cameras:
                    if camera_name.lower() in camera['name'].lower():
                        print(f"âœ… Found camera '{camera_name}' at index {camera['index']} (via scan)")
                        return camera['index']
                return None
            
            # Parse the output to find matching camera
            devices = json.loads(result.stdout)
            if not isinstance(devices, list):
                devices = [devices]
            
            print(f"Found {len(devices)} camera-like devices in Windows")
            current_index = 0
            for device in devices:
                device_name = device.get('Name', '')
                print(f"  Checking device {current_index}: {device_name} (Class: {device.get('PNPClass', 'Unknown')})")
                
                # Case-insensitive search for Iriun
                search_name = camera_name.lower()
                if "iriun" in search_name or "iriun" in device_name.lower():
                    # Special handling for Iriun
                    if "iriun" in device_name.lower():
                        print(f"âœ… Found Iriun Webcam at index {current_index}")
                        return current_index
                
                # General name matching
                if search_name in device_name.lower() or device_name.lower() in search_name:
                    print(f"âœ… Found camera '{camera_name}' at index {current_index}")
                    return current_index
                
                # Increment index if this is a camera-like device
                if "Camera" in device_name or "Image" in device.get('PNPClass', ''):
                    current_index += 1
            
            # If not found by exact name, try scanning available cameras
            print("Camera not found by name, scanning available cameras...")
            available_cameras = self.scan_available_cameras()
            for camera in available_cameras:
                if camera_name.lower() in camera['name'].lower() or "iriun" in camera_name.lower() and "iriun" in camera['name'].lower():
                    print(f"âœ… Found camera '{camera_name}' at index {camera['index']} (via scan)")
                    return camera['index']
            
            print(f"âŒ Camera '{camera_name}' not found in device list")
            return None
            
        except Exception as e:
            print(f"Error finding camera by name: {e}")
            import traceback
            traceback.print_exc()
            return None


class AnonymizerWorker(threading.Thread):
    """
    Worker thread do offline anonimizacji osÃ³b (gÃ³rna czÄ™Å›Ä‡ ciaÅ‚a).
    
    UÅ¼ywa YOLOv8 do wykrywania osÃ³b, zamazuje tylko gÅ‚owÄ™ i ramiona.
    DziaÅ‚a asynchronicznie - nie blokuje gÅ‚Ã³wnej pÄ™tli kamery.
    ObsÅ‚uguje rÃ³wnieÅ¼ powiadomienia SMS przez Twilio i Google Drive.
    """
    
    def __init__(self, detection_queue, settings, blur_kernel_size=99, blur_sigma=30, upper_body_ratio=0.50):
        super().__init__(daemon=True)
        self.detection_queue = detection_queue
        self.settings = settings  # Referencja do settings z CameraController
        self.blur_kernel_size = blur_kernel_size
        self.blur_sigma = blur_sigma
        self.upper_body_ratio = upper_body_ratio  # Jaki procent gÃ³rnej czÄ™Å›ci bbox osoby zamazaÄ‡
        self.is_running = True
        
        # Statystyki
        self.tasks_processed = 0
        self.persons_anonymized = 0
        
        # Inicjalizacja YOLOv8 dla detekcji osÃ³b
        print("ðŸ“· Inicjalizacja YOLOv8 dla detekcji osÃ³b (anonimizacja)...")
        
        try:
            # ZaÅ‚aduj model YOLOv8 (ten sam, ktÃ³ry wykrywa telefony)
            self.model = YOLO('yolov8n.pt')
            print("âœ… YOLOv8 zainicjalizowany dla anonimizacji")
            print(f"   Zamazywanie gÃ³rnych {int(self.upper_body_ratio * 100)}% ciaÅ‚a osoby")
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d Å‚adowania YOLOv8: {e}")
            self.model = None
        
        # Inicjalizacja klienta Vonage (Nexmo) dla SMS
        print("ðŸ“± Inicjalizacja klienta Vonage...")
        try:
            self.vonage_api_key = os.getenv('VONAGE_API_KEY')
            self.vonage_api_secret = os.getenv('VONAGE_API_SECRET')
            self.vonage_from_number = os.getenv('VONAGE_FROM_NUMBER', 'PhoneDetection')
            self.vonage_to_number = os.getenv('VONAGE_TO_NUMBER')
            
            if all([self.vonage_api_key, self.vonage_api_secret, self.vonage_to_number]):
                # Vonage v4+ uÅ¼ywa Auth â†’ HttpClient â†’ Sms
                vonage_auth = Auth(api_key=self.vonage_api_key, api_secret=self.vonage_api_secret)
                vonage_http_client = HttpClient(vonage_auth)
                self.vonage_sms = Sms(vonage_http_client)
                print("âœ… Klient Vonage zainicjalizowany")
            else:
                self.vonage_sms = None
                print("âš ï¸  Brak danych Vonage w zmiennych Å›rodowiskowych")
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d inicjalizacji Vonage: {e}")
            self.vonage_sms = None
        
        # Inicjalizacja Cloudinary
        print("â˜ï¸  Inicjalizacja Cloudinary...")
        try:
            cloudinary_cloud_name = os.getenv('CLOUDINARY_CLOUD_NAME')
            cloudinary_api_key = os.getenv('CLOUDINARY_API_KEY')
            cloudinary_api_secret = os.getenv('CLOUDINARY_API_SECRET')
            
            if all([cloudinary_cloud_name, cloudinary_api_key, cloudinary_api_secret]):
                cloudinary.config(
                    cloud_name=cloudinary_cloud_name,
                    api_key=cloudinary_api_key,
                    api_secret=cloudinary_api_secret,
                    secure=True
                )
                self.cloudinary_enabled = True
                print("âœ… Cloudinary zainicjalizowane")
                print(f"   Cloud Name: {cloudinary_cloud_name}")
            else:
                self.cloudinary_enabled = False
                print("âš ï¸  Brak danych Cloudinary w zmiennych Å›rodowiskowych")
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d inicjalizacji Cloudinary: {e}")
            self.cloudinary_enabled = False
        
        # Inicjalizacja Email (yagmail) - przechowujemy tylko dane logowania
        print("ðŸ“§ Inicjalizacja danych Email (Yagmail)...")
        try:
            # Pobierz dane logowania z zmiennych Å›rodowiskowych (.env)
            self.email_user = os.environ.get("GMAIL_USER")
            self.email_password = os.environ.get("GMAIL_APP_PASSWORD")
            self.email_recipient = os.environ.get("EMAIL_RECIPIENT")
            
            # SprawdÅº czy wszystkie dane sÄ… dostÄ™pne
            if not all([self.email_user, self.email_password, self.email_recipient]):
                print("âš ï¸  Brak danych Email w zmiennych Å›rodowiskowych (.env)")
                print("   Wymagane: GMAIL_USER, GMAIL_APP_PASSWORD, EMAIL_RECIPIENT")
            else:
                # NIE tworzymy poÅ‚Ä…czenia tutaj - bÄ™dzie tworzone przy kaÅ¼dej wysyÅ‚ce
                print("âœ… Dane Email zainicjalizowane (poÅ‚Ä…czenie bÄ™dzie tworzone przy wysyÅ‚ce).")
                print(f"   WysyÅ‚ka z: {self.email_user}")
                print(f"   Odbiorca: {self.email_recipient}")
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d inicjalizacji danych Email: {e}")
    
    def run(self):
        """GÅ‚Ã³wna pÄ™tla workera - przetwarza zadania z kolejki"""
        print("ðŸ”„ AnonymizerWorker uruchomiony")
        
        while self.is_running:
            try:
                # Pobierz zadanie z kolejki (blokujÄ…ce z timeout)
                try:
                    task_data = self.detection_queue.get(timeout=1)
                except:
                    continue  # Timeout - sprawdÅº is_running i prÃ³buj ponownie
                
                if task_data is None:
                    # SygnaÅ‚ zakoÅ„czenia
                    self.detection_queue.task_done()
                    break
                
                filepath = task_data.get('filepath')
                confidence = task_data.get('confidence', 0.0)
                # KLUCZOWE: Odczytaj flagÄ™ should_blur (domyÅ›lnie True dla bezpieczeÅ„stwa)
                should_blur = task_data.get('should_blur', True)
                
                print(f"ðŸ”„ Przetwarzanie: {filepath} (blur: {should_blur})")
                
                # Wykonaj anonimizacjÄ™ TYLKO jeÅ›li should_blur = True
                if should_blur:
                    success = self._anonymize_faces(filepath)
                    
                    if success:
                        print(f"âœ… Zanonimizowano: {filepath}")
                        self.tasks_processed += 1
                    else:
                        print(f"âŒ BÅ‚Ä…d anonimizacji: {filepath}")
                else:
                    # Blur wyÅ‚Ä…czony - pomiÅ„ anonimizacjÄ™ caÅ‚kowicie
                    print(f"â­ï¸  Pomijam anonimizacjÄ™ (blur wyÅ‚Ä…czony): {filepath}")
                    self.tasks_processed += 1
                
                # ZAWSZE zapisz do bazy danych (niezaleÅ¼nie od blur)
                # JeÅ›li blur=False, zapisujemy oryginalny plik
                # JeÅ›li blur=True, zapisujemy zanonimizowany plik
                self._save_to_database(task_data)
                
                # KLUCZOWY WARUNEK: SprawdÅº czy KTÃ“RYKOLWIEK rodzaj powiadomieÅ„ jest wÅ‚Ä…czony
                sms_enabled = self.settings.get('sms_notifications', False)
                email_enabled = self.settings.get('email_notifications', False)
                
                if sms_enabled or email_enabled:
                    notification_types = []
                    if sms_enabled:
                        notification_types.append("SMS")
                    if email_enabled:
                        notification_types.append("Email")
                    
                    print(f"ðŸ“² Powiadomienia wÅ‚Ä…czone ({', '.join(notification_types)}) - uruchamiam wysyÅ‚kÄ™ w tle")
                    # Uruchom w osobnym wÄ…tku aby nie blokowaÄ‡ pÄ™tli run
                    notification_thread = threading.Thread(
                        target=self._handle_cloud_notification,
                        args=(filepath, confidence, zone_name),
                        daemon=True
                    )
                    notification_thread.start()
                else:
                    print(f"ðŸ“µ Powiadomienia (Email/SMS) wyÅ‚Ä…czone - pomijam wysyÅ‚kÄ™")
                
                self.detection_queue.task_done()
                
            except Exception as e:
                print(f"âŒ BÅ‚Ä…d w AnonymizerWorker: {e}")
                try:
                    self.detection_queue.task_done()
                except:
                    pass
        
        print(f"ðŸ›‘ AnonymizerWorker zakoÅ„czyÅ‚ (zadania: {self.tasks_processed}, osoby: {self.persons_anonymized})")
    
    def _upload_to_cloudinary(self, filepath):
        """
        WysyÅ‚a plik na Cloudinary i zwraca publiczny link.
        
        Args:
            filepath: ÅšcieÅ¼ka do pliku
            
        Returns:
            secure_url (str) lub None jeÅ›li bÅ‚Ä…d
        """
        try:
            if not self.cloudinary_enabled:
                print("âŒ Cloudinary nie jest zainicjalizowane")
                return None
            
            filename = os.path.basename(filepath)
            
            print(f"â˜ï¸  WysyÅ‚anie {filename} na Cloudinary...")
            
            # Upload pliku na Cloudinary
            response = cloudinary.uploader.upload(
                filepath,
                folder="phone_detections",  # Folder w Cloudinary
                public_id=os.path.splitext(filename)[0],  # Nazwa bez rozszerzenia
                resource_type="image",
                overwrite=True
            )
            
            # Pobierz secure URL (HTTPS)
            secure_url = response.get('secure_url')
            public_id = response.get('public_id')
            
            print(f"âœ… Plik wysÅ‚any na Cloudinary: {public_id}")
            print(f"ðŸ”— Link (publiczny): {secure_url}")
            
            return secure_url
            
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d wysyÅ‚ania na Cloudinary: {e}")
            return None
    
    def _send_sms_notification(self, public_link, confidence, zone_name=None):
        """
        WysyÅ‚a powiadomienie SMS przez Vonage (Nexmo).
        
        Args:
            public_link: Link do pliku na Google Drive (lub None jeÅ›li upload siÄ™ nie powiÃ³dÅ‚)
            confidence: PewnoÅ›Ä‡ detekcji
            zone_name: Nazwa strefy (np. "Å‚awka 1") lub None
            
        Returns:
            True jeÅ›li sukces, False w przeciwnym razie
        """
        try:
            if self.vonage_sms is None:
                print("âŒ Klient Vonage nie jest zainicjalizowany")
                return False
            
            # Przygotuj treÅ›Ä‡ wiadomoÅ›ci
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            location = zone_name or self.settings.get('camera_name', 'Camera 1')
            
            if public_link:
                message_body = (
                    f"Phone Detection Alert!\n"
                    f"Time: {timestamp}\n"
                    f"Location: {location}\n"
                    f"Confidence: {confidence:.2%}\n"
                    f"Image: {public_link}\n"
                    f"---"  # Padding dla Vonage demo - chroni link przed [FREE SMS DEMO...]
                )
            else:
                # WyÅ›lij SMS bez linku jeÅ›li Cloudinary zawiÃ³dÅ‚
                message_body = (
                    f"Phone Detection Alert!\n"
                    f"Time: {timestamp}\n"
                    f"Location: {location}\n"
                    f"Confidence: {confidence:.2%}\n"
                    f"(Image upload failed)\n"
                    f"---"  # Padding dla Vonage demo
                )
            
            # Vonage wymaga numeru bez '+' i jako string
            to_number = self.vonage_to_number.replace('+', '')
            
            print(f"ðŸ“± WysyÅ‚anie SMS na +{to_number}...")
            
            # StwÃ³rz obiekt SmsMessage (Vonage v4 API)
            sms_message = SmsMessage(
                to=to_number,
                from_=self.vonage_from_number,
                text=message_body
            )
            
            # WyÅ›lij SMS przez Vonage v4
            response = self.vonage_sms.send(sms_message)
            
            # SprawdÅº odpowiedÅº
            if response and hasattr(response, 'messages'):
                if response.messages[0].status == '0':
                    message_id = response.messages[0].message_id
                    print(f"âœ… SMS wysÅ‚any: {message_id}")
                    return True
                else:
                    error = getattr(response.messages[0], 'error_text', 'Unknown error')
                    print(f"âŒ BÅ‚Ä…d Vonage: {error}")
                    return False
            else:
                print(f"âŒ NieprawidÅ‚owa odpowiedÅº Vonage: {response}")
                return False
            
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d wysyÅ‚ania SMS: {e}")
            return False
    
    def _send_email_notification(self, public_link, filepath, confidence, location):
        """
        WysyÅ‚a powiadomienie e-mail przez Yagmail z osadzonym obrazem.
        Tworzy nowe, Å›wieÅ¼e poÅ‚Ä…czenie SMTP przy kaÅ¼dej wysyÅ‚ce.
        
        Args:
            public_link: Link do pliku na Cloudinary
            filepath: Lokalna Å›cieÅ¼ka do pliku (dla osadzenia i zaÅ‚Ä…cznika)
            confidence: PewnoÅ›Ä‡ detekcji
            location: Nazwa kamery/lokalizacji
            
        Returns:
            True jeÅ›li sukces, False w przeciwnym razie
        """
        # SprawdÅº, czy dane email sÄ… dostÄ™pne
        if not all([self.email_user, self.email_password, self.email_recipient]):
            print("âš ï¸ Brak danych Email. Pomijam wysyÅ‚kÄ™.")
            return False
        
        try:
            subject = f"Wykryto Telefon! ({location})"
            
            # --- Definicja TreÅ›ci ---
            body_content = [
                "<b>Wykryto Telefon!</b>",
                "<hr>",
                f"<b>Lokalizacja:</b> {location}",
                 f"<b>PewnoÅ›Ä‡ detekcji:</b> {(confidence * 100):.1f}%",
                "<br>",
                "Zanonimizowany obraz (osadzony poniÅ¼ej i w zaÅ‚Ä…czniku):",
                yagmail.inline(filepath)  # Osadzenie obrazu
            ]
            
            # Opcjonalnie: dodaj link do Cloudinary
            if public_link and public_link != "(Upload do Cloudinary nie powiÃ³dÅ‚ siÄ™)":
                body_content.append(f'<br><a href="{public_link}">Link do obrazu w chmurze</a>')
            
            # --- Nowa Logika PoÅ‚Ä…czenia ---
            # Tworzymy nowe, Å›wieÅ¼e poÅ‚Ä…czenie przy kaÅ¼dej wysyÅ‚ce
            with yagmail.SMTP(self.email_user, self.email_password) as yag_client:
                yag_client.send(
                    to=self.email_recipient,
                    subject=subject,
                    contents=body_content,
                    attachments=filepath
                )
            # PoÅ‚Ä…czenie jest automatycznie zamykane po wyjÅ›ciu z bloku "with"
            
            print(f"âœ… PomyÅ›lnie wysÅ‚ano e-mail (z osadzonym obrazem) do {self.email_recipient}")
            return True
            
        except smtplib.SMTPDataError as e:
            # Specjalna obsÅ‚uga "faÅ‚szywego" bÅ‚Ä™du 250 OK
            if e.smtp_code == 250:
                print(f"âœ… E-mail prawdopodobnie wysÅ‚any (otrzymano kod 250 OK), ale wystÄ…piÅ‚ wyjÄ…tek: {e}")
                return True
            else:
                print(f"âŒ BÅ‚Ä…d krytyczny wysyÅ‚ania e-mail (Yagmail SMTPDataError): {e}")
                import traceback
                traceback.print_exc()
                return False
                
        except Exception as e:
            # Inne bÅ‚Ä™dy
            print(f"âŒ BÅ‚Ä…d krytyczny wysyÅ‚ania e-mail (Yagmail): {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _handle_cloud_notification(self, filepath, confidence, zone_name=None):
        """
        Orkiestrator powiadomieÅ„ - upload na Cloudinary i wysyÅ‚ka SMS/Email.
        
        Args:
            filepath: ÅšcieÅ¼ka do pliku
            confidence: PewnoÅ›Ä‡ detekcji
            zone_name: Nazwa strefy (np. "Å‚awka 1") lub None
        """
        try:
            print(f"ðŸš€ Rozpoczynam wysyÅ‚kÄ™ powiadomienia dla: {filepath}")
            
            # 1. PrÃ³buj upload na Cloudinary (opcjonalnie)
            public_link = self._upload_to_cloudinary(filepath)
            
            if public_link:
                print(f"âœ… Plik wysÅ‚any na Cloudinary")
                
                # 2. WyÅ›lij SMS jeÅ›li wÅ‚Ä…czony
                if self.settings.get('sms_notifications', False):
                    print("ðŸ“± SMS notifications wÅ‚Ä…czone - wysyÅ‚anie...")
                    success = self._send_sms_notification(public_link, confidence, zone_name)
                    if success:
                        print(f"âœ… SMS wysÅ‚any z linkiem do zdjÄ™cia!")
                    else:
                        print(f"âŒ Nie udaÅ‚o siÄ™ wysÅ‚aÄ‡ SMS")
                else:
                    print("ðŸ“µ SMS notifications wyÅ‚Ä…czone - pomijam SMS")
                
                # 3. WyÅ›lij Email jeÅ›li wÅ‚Ä…czony
                if self.settings.get('email_notifications', False):
                    print("ðŸ“§ Email notifications wÅ‚Ä…czone - wysyÅ‚anie...")
                    location = zone_name or self.settings.get('camera_name', 'Camera 1')
                    self._send_email_notification(
                        public_link,
                        filepath,
                        confidence,
                        location
                    )
                else:
                    print("ðŸ“­ Email notifications wyÅ‚Ä…czone - pomijam e-mail")
            else:
                # Cloudinary zawiodÅ‚o - wyÅ›lij powiadomienia bez linku
                print("âš ï¸  Nie udaÅ‚o siÄ™ wysÅ‚aÄ‡ na Cloudinary")
                
                if self.settings.get('sms_notifications', False):
                    print("   ale wyÅ›lÄ™ SMS bez linku")
                    success = self._send_sms_notification(None, confidence, zone_name)
                    if success:
                        print(f"âœ… SMS wysÅ‚any (bez linku)")
                    else:
                        print(f"âŒ Nie udaÅ‚o siÄ™ wysÅ‚aÄ‡ SMS")
                
                # Email z informacjÄ… o braku linku
                if self.settings.get('email_notifications', False):
                    print("ðŸ“§ Email notifications wÅ‚Ä…czone - wysyÅ‚anie (bez linku Cloudinary)...")
                    location = zone_name or self.settings.get('camera_name', 'Camera 1')
                    # WyÅ›lij z tekstem zamiast linku
                    self._send_email_notification(
                        "(Upload do Cloudinary nie powiÃ³dÅ‚ siÄ™)",
                        filepath,
                        confidence,
                        location
                    )
                
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d w _handle_cloud_notification: {e}")
    
    def _anonymize_faces(self, image_path):
        """
        Anonimizuje gÃ³rnÄ… czÄ™Å›Ä‡ ciaÅ‚a osÃ³b (gÅ‚owa + ramiona) uÅ¼ywajÄ…c YOLOv8.
        
        Strategia:
        - Wykrywa osoby (klasa 0) za pomocÄ… YOLOv8
        - Dla kaÅ¼dej osoby zamazuje tylko gÃ³rnÄ… czÄ™Å›Ä‡ bbox (30-40%)
        - JeÅ›li brak osÃ³b - zapisuje oryginaÅ‚ bez zmian
        
        Args:
            image_path: ÅšcieÅ¼ka do obrazu
            
        Returns:
            True jeÅ›li sukces
        """
        try:
            # SprawdÅº czy model jest dostÄ™pny
            if self.model is None:
                print("âš ï¸  Model YOLOv8 niedostÄ™pny, zapisujÄ™ oryginaÅ‚")
                return True  # Brak modelu = zapisz oryginaÅ‚
            
            # Wczytaj obraz
            image = cv2.imread(image_path)
            if image is None:
                print(f"âŒ Nie moÅ¼na wczytaÄ‡: {image_path}")
                return False
            
            # Pobierz wymiary obrazu
            img_h, img_w = image.shape[:2]
            
            # Wykryj osoby za pomocÄ… YOLOv8
            results = self.model(image, verbose=False)
            
            persons_found = 0
            
            # PrzetwÃ³rz wyniki
            for result in results:
                boxes = result.boxes
                for box in boxes:
                    class_id = int(box.cls[0])
                    confidence = float(box.conf[0])
                    
                    # Szukamy tylko klasy 'person' (0 w COCO)
                    if class_id == 0 and confidence >= 0.5:
                        persons_found += 1
                        
                        # Pobierz peÅ‚ny bounding box osoby
                        x1, y1, x2, y2 = map(int, box.xyxy[0])
                        
                        # Oblicz wysokoÅ›Ä‡ bbox osoby
                        person_height = y2 - y1
                        
                        # Oblicz gÃ³rnÄ… czÄ™Å›Ä‡ ciaÅ‚a (konfigurowalny % od gÃ³ry)
                        try:
                            percent = int(self.settings.get('anonymization_percent', 50))
                        except Exception:
                            percent = 50
                        ratio = max(0, min(100, percent)) / 100.0
                        upper_body_height = int(person_height * ratio)
                        
                        # Definiuj ROI dla gÃ³rnej czÄ™Å›ci ciaÅ‚a
                        # X: caÅ‚y bbox osoby (lewa-prawa)
                        # Y: tylko gÃ³rna czÄ™Å›Ä‡
                        roi_x1 = x1
                        roi_y1 = y1
                        roi_x2 = x2
                        roi_y2 = y1 + upper_body_height
                        
                        # Walidacja granic obrazu
                        roi_x1 = max(0, roi_x1)
                        roi_y1 = max(0, roi_y1)
                        roi_x2 = min(img_w, roi_x2)
                        roi_y2 = min(img_h, roi_y2)
                        
                        # SprawdÅº czy ROI ma sens
                        if roi_x2 <= roi_x1 or roi_y2 <= roi_y1:
                            print(f"âš ï¸  NieprawidÅ‚owy ROI osoby: ({roi_x1},{roi_y1})-({roi_x2},{roi_y2}), pomijam")
                            continue
                        
                        # Wytnij ROI gÃ³rnej czÄ™Å›ci ciaÅ‚a
                        upper_body_roi = image[roi_y1:roi_y2, roi_x1:roi_x2]
                        
                        # Zastosuj silny Gaussian blur
                        if upper_body_roi.size > 0:
                            blurred_upper_body = cv2.GaussianBlur(
                                upper_body_roi,
                                (self.blur_kernel_size, self.blur_kernel_size),
                                self.blur_sigma
                            )
                            image[roi_y1:roi_y2, roi_x1:roi_x2] = blurred_upper_body
                            self.persons_anonymized += 1
                            print(f"  âœ“ Zanonimizowano osobÄ™ #{persons_found}: gÃ³rne {int(ratio*100)}% ciaÅ‚a (conf: {confidence:.2f})")
                        else:
                            print(f"âš ï¸  Pusty ROI dla osoby, pomijam")
            
            if persons_found == 0:
                print(f"â„¹ï¸  Brak osÃ³b na obrazie - zapisujÄ™ oryginaÅ‚ bez zmian")
            else:
                print(f"ðŸ‘¤ Zanonimizowano {persons_found} osÃ³b (tylko gÃ³rna czÄ™Å›Ä‡ ciaÅ‚a)")
            
            # Nadpisz oryginalny plik (zanonimizowanym lub oryginalnym jeÅ›li brak osÃ³b)
            success = cv2.imwrite(image_path, image)
            
            if not success:
                print(f"âŒ Nie udaÅ‚o siÄ™ zapisaÄ‡: {image_path}")
                return False
            
            return True
            
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d anonimizacji: {e}")
            return False
    
    def _save_to_database(self, detection_data):
        """Zapisuje wykrycie do bazy danych (tylko zanonimizowany obraz)"""
        try:
            from app import app
            filepath = detection_data.get('filepath')
            confidence = detection_data.get('confidence', 0.0)
            zone_name = detection_data.get('zone_name')
            filename = os.path.basename(filepath)
            
            with app.app_context():
                admin_user = User.query.filter_by(username='admin').first()
                if admin_user:
                    # UÅ¼yj zone_name jeÅ›li dostÄ™pne, w przeciwnym razie uÅ¼yj nazwy kamery
                    location = zone_name or self.settings.get('camera_name', 'Camera 1')
                    detection = Detection(
                        location=location,
                        confidence=confidence,
                        image_path=filename,
                        status='Pending',
                        user_id=admin_user.id
                    )
                    db.session.add(detection)
                    db.session.commit()
                    print(f"ðŸ’¾ Zapisano do DB: {filename} (strefa: {location})")
                else:
                    print("âŒ Brak uÅ¼ytkownika admin")
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d zapisu do DB: {e}")
    
    def stop(self):
        """Zatrzymuje workera"""
        self.is_running = False


# PrzykÅ‚ad uÅ¼ycia
if __name__ == "__main__":
    cameras = CameraController.scan_available_cameras()
    for camera in cameras:
        print(f"Camera {camera['index']}: {camera['name']} ({camera['resolution']}, {camera['fps']} FPS)")